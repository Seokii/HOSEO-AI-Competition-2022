{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0306a798",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ddb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel, ElectraModel, ElectraTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820287d6",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73756656",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", encoding='CP949')\n",
    "test = pd.read_csv(\"test.csv\", encoding='CP949')\n",
    "sub = pd.read_csv(\"sample.csv\", encoding='CP949')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc15a6b4",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e28c0",
   "metadata": {},
   "source": [
    "### .head() 함수로 데이터셋에 대한 기본 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9eecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1c1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fd43d",
   "metadata": {},
   "source": [
    "train 19996개, test 5000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd28c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"train shape => {train.shape} \\ntest shape => {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fa413",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c52e08",
   "metadata": {},
   "source": [
    "### LabelEncoder를 활용해 categorical features를 encode함\n",
    "contradiction => 0  \n",
    "entailment => 1  \n",
    "neutral => 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d611c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['label']\n",
    "for e in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[e] = le.fit_transform(train[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f97655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e1b076",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76809a08",
   "metadata": {},
   "source": [
    "### 라벨값이 balaced 한지 imbalanced 한지 확인하는 visualization\n",
    "만약 학습 데이터가 imbalanced 하다면, 추가적인 고민이 필요하지만  \n",
    "시각화 결과 클래스 값들이 고르게 분포되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56852407",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"label\", data=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, frequencies = np.unique(train.label.values, return_counts=True)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(frequencies, labels = labels, autopct= '%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764a68d",
   "metadata": {},
   "source": [
    "### 훈련 데이터 결측치 계산  \n",
    "없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b82bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbfe994",
   "metadata": {},
   "source": [
    "## Modeling - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da984c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "model_name = \"monologg/koelectra-base-v3-discriminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b256ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "    tokens = list(tokenizer.tokenize(s))\n",
    "    tokens.append('[SEP]')\n",
    "    return tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dcde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"안녕하세요. 인코딩 테스트 문장입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654e885",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_sentence(\"안녕하세요. 인코딩 테스트 문장입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(hypotheses, premises, tokenizer):\n",
    "    \n",
    "    sentence1 = tf.ragged.constant([\n",
    "        encode_sentence(s)\n",
    "        for s in np.array(hypotheses)])\n",
    "    sentence2 = tf.ragged.constant([\n",
    "        encode_sentence(s)\n",
    "        for s in np.array(premises)])\n",
    "    \n",
    "    cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
    "    input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
    "    \n",
    "    input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "    \n",
    "    type_cls = tf.zeros_like(cls)\n",
    "    type_s1 = tf.zeros_like(sentence1)\n",
    "    type_s2 = tf.ones_like(sentence2)\n",
    "    input_type_ids = tf.concat(\n",
    "        [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
    "    \n",
    "    inputs = {\n",
    "        'input_word_ids': input_word_ids.to_tensor(),\n",
    "        'input_mask': input_mask,\n",
    "        'input_type_ids': input_type_ids}\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09abb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.premise.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.hypothesis.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cf9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(train.hypothesis.values, train.premise.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e62c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34df9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFElectraModel\n",
    "\n",
    "max_len = 98\n",
    "\n",
    "def build_model():\n",
    "    bert_encoder = TFElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", from_pt=True)\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "    \n",
    "    embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n",
    "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7676d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_input, train.label.values, epochs = 2, verbose = 1, batch_size = 32, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = bert_encode(test.premise.values, test.hypothesis.values, tokenizer)\n",
    "predictions = [np.argmax(i) for i in model.predict(test_input)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a63986",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test.id.copy().to_frame()\n",
    "submission['prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
